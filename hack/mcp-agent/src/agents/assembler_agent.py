from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

def create_assembler_agent():
    """Create an agent to assemble all sections into a complete MCP YAML file."""
    system_message = """You are an expert at assembling MCP YAML files.
    Your task is to take the individual sections generated by specialized agents and assemble them into a complete, properly formatted <mcp>.yaml file.
    
    Ensure that:
    1. All sections are properly nested according to the schema
    2. The YAML is properly formatted with correct indentation
    3. The structure follows the required schema with these main sections:
       - Metadata (at the root level) - No Metadata section is needed
       - tools
       - source
       - build
       - run (containing config, entrypoint, and env)
    
    Correct any obvious formatting issues between sections while preserving the content.
    Do not add new content or remove existing content unless necessary for proper YAML formatting.
    
    Return ONLY the YAML content, nothing else.
    """
    
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        ("human", "Assemble these sections into a complete MCP YAML file:\n\n"
                "Metadata Section:\n{metadata_section}\n\n"
                "Tools Section:\n{tools_section}\n\n"
                "Source Section:\n{source_section}\n\n"
                "Build Section:\n{build_section}\n\n"
                "Config Section:\n{config_section}\n\n"
                "Entrypoint Section:\n{entrypoint_section}\n\n"
                "Env Section:\n{env_section}\n\n"
                "Please generate the complete MCP YAML file with proper formatting.")
    ])
    
    chain = prompt | llm | StrOutputParser()
    return chain 